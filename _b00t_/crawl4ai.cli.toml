[b00t]
name = "crawl4ai"
type = "cli"
hint = "crawl4ai - AI-powered web crawler with LLM-ready markdown output"
desires = "0.7.6"
keywords = ["web-scraping", "crawler", "markdown", "ai", "llm"]

# Installation via uv tool (b00t standard)
install = """
# ü§ì Self-healing: ensure uv is available before tool install
if ! command -v uv >/dev/null 2>&1; then
    echo "ü•æ uv required for crawl4ai installation"
    if command -v b00t >/dev/null 2>&1; then
        echo "üîß Auto-installing uv via b00t..."
        b00t cli install uv
        if [ $? -ne 0 ]; then
            echo "‚ùå Failed to install uv via b00t"
            exit 1
        fi
    else
        echo "üí° Install uv: curl -LsSf https://astral.sh/uv/install.sh | sh"
        exit 1
    fi
fi

# Install crawl4ai with all dependencies
uv tool install crawl4ai[all]

# Verify installation
if ! command -v crawl4ai >/dev/null 2>&1; then
    echo "‚ùå crawl4ai installation failed"
    exit 1
fi

echo "‚úÖ crawl4ai installed successfully"
"""

# Update to latest version
update = """
uv tool upgrade crawl4ai
"""

# Version detection
version = "crawl4ai --version"
version_regex = "crawl4ai version (\\d+\\.\\d+\\.\\d+)"

aliases = ["crawl", "crawl-fast", "crawl-deep", "crawl-js", "crawl-wait"]

[[b00t.aliases]]
name = "crawl"
command = "crawl4ai"

[[b00t.aliases]]
name = "crawl-fast"
command = "crawl4ai --mode fast"

[[b00t.aliases]]
name = "crawl-deep"
command = "crawl4ai --mode deep"

[[b00t.aliases]]
name = "crawl-js"
command = "crawl4ai --browser"

[[b00t.aliases]]
name = "crawl-wait"
command = "crawl4ai --wait"
[b00t.env]
# User agent for crawl4ai requests
CRAWL4AI_USER_AGENT = "b00t-crawler/0.7 (https://github.com/elasticdotventures/_b00t_)"
# Output directory for crawled content
CRAWL4AI_OUTPUT_DIR = "~/.b00t/crawls"
# Browser executable path (optional)
CRAWL4AI_BROWSER_PATH = ""
# Enable verbose logging
CRAWL4AI_VERBOSE = "false"

[[b00t.usage]]
description = "Basic URL crawling"
command = "crawl4ai https://example.com"

[[b00t.usage]]
description = "Markdown output"
command = "crawl4ai https://example.com --format markdown"

[[b00t.usage]]
description = "Deep crawl with links"
command = "crawl4ai https://example.com --depth 2 --max-pages 10"

[[b00t.usage]]
description = "Wait for dynamic content"
command = "crawl4ai https://example.com --wait-for 'css:.loaded'"

[[b00t.usage]]
description = "Extract specific CSS selector"
command = "crawl4ai https://example.com --css-selector '.article-content'"

[[b00t.usage]]
description = "Output to file"
command = "crawl4ai https://example.com --output ~/crawls/example.md"

[[b00t.usage]]
description = "Custom user agent"
command = "crawl4ai https://example.com --user-agent 'b00t-crawler'"

[[b00t.usage]]
description = "Fast mode (no JS rendering)"
command = "crawl4ai https://example.com --mode fast"

[b00t.learn]
# crawl4ai CLI documentation and patterns
content = """
# crawl4ai CLI Usage

crawl4ai is an AI-powered web crawler that outputs LLM-ready markdown.

## Basic Commands

```bash
# Simple crawl
crawl4ai https://docs.python.org/3/

# Markdown output
crawl4ai https://example.com --format markdown

# Save to file
crawl4ai https://example.com --output ~/crawls/example.md

# Custom user agent (identify as b00t)
crawl4ai https://example.com --user-agent "b00t-crawler/0.7"
```

## Advanced Features

```bash
# Deep crawl (follow links)
crawl4ai https://docs.langchain.com --depth 2 --max-pages 20

# Wait for dynamic content
crawl4ai https://spa-site.com --wait-for "css:.loaded"

# Extract specific content
crawl4ai https://example.com --css-selector "article.main"

# Execute JavaScript
crawl4ai https://example.com --js-code "window.scrollTo(0, document.body.scrollHeight)"

# Fast mode (no browser rendering)
crawl4ai https://example.com --mode fast
```

## Output Formats

- `markdown` (default): Clean markdown, LLM-friendly
- `html`: Raw HTML
- `text`: Plain text
- `json`: Structured JSON with metadata

## Integration with b00t

```bash
# Crawl and learn from URL
crawl4ai https://docs.langchain.com/oss/python/releases/langchain-v1 \\
  --format markdown \\
  --output ~/.b00t/crawls/langchain-v1.md \\
  --user-agent "b00t-crawler"

# Then ingest into grok
b00t-cli grok learn ~/.b00t/crawls/langchain-v1.md
```

## Browser Configuration

crawl4ai uses Playwright for browser automation:

```bash
# Install browsers (first time)
playwright install chromium

# Or all browsers
playwright install
```

## Tips

1. **Use --mode fast** for static sites (faster, no JS rendering)
2. **Set --user-agent** to identify as b00t
3. **Use --css-selector** to extract specific content
4. **Enable --depth** for documentation sites with multiple pages
5. **Save to ~/.b00t/crawls/** for organized storage
"""

depends_on = ["python.cli", "playwright"]
