# b00t-j0b-py Environment Configuration
# ==========================================
# This file shows required environment variables for b00t-j0b-py.
# API keys are loaded via direnv → .envrc → dotenv → .env pattern.
#
# Setup:
#   1. Copy: cp .env.example .env
#   2. Fill in your actual API keys in .env
#   3. Enable: direnv allow (after copying .envrc.example to .envrc)
#
# The b00t pattern:
#   - Datums (~/.dotfiles/_b00t_/*.ai.toml) specify WHICH vars are required
#   - This .env file contains the actual VALUES
#   - direnv loads them automatically when entering the directory

# Redis Configuration (Required)
REDIS_URL=redis://localhost:6379/0

# Crawler Configuration
CRAWLER_USER_AGENT=b00t-j0b-py/0.1.0 (+https://github.com/elasticdotventures/dotfiles)
CRAWLER_DELAY=1.0
CRAWLER_MAX_DEPTH=3
CRAWLER_TIMEOUT=30

# Content Processing
MAX_CONTENT_SIZE=10485760  # 10MB
CHUNK_SIZE=8192

# Job Configuration
RQ_DEFAULT_QUEUE=default
RQ_HIGH_QUEUE=high
RQ_LOW_QUEUE=low

# ==========================================
# AI Provider API Keys (for pydantic-ai agents)
# ==========================================
# Keys are loaded from this .env file via direnv.
# Datums validate that required keys are present.
# Only add keys for providers you plan to use.

# OpenAI (gpt-4, gpt-3.5-turbo, etc.)
# OPENAI_API_KEY=sk-proj-...

# Anthropic (claude-3.5-sonnet, claude-3-opus, etc.)
# ANTHROPIC_API_KEY=sk-ant-api03-...

# Google Gemini (gemini-1.5-pro, gemini-1.5-flash, etc.)
# GOOGLE_API_KEY=...
# Or for Vertex AI:
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Groq (llama-3.1, mixtral, etc. - ultra-fast inference)
# GROQ_API_KEY=gsk_...

# OpenRouter (200+ models via single API)
# OPENROUTER_API_KEY=sk-or-...
# OPENROUTER_API_BASE=https://openrouter.ai/api/v1  # Optional, has default

# HuggingFace (inference API for open models)
# HUGGINGFACE_TOKEN=hf_...
# HUGGINGFACE_API_BASE=https://api-inference.huggingface.co/models  # Optional

# Ollama (local models)
# OLLAMA_BASE_URL=http://localhost:11434  # Optional, has default
# OLLAMA_API_KEY=...  # Only if using remote Ollama with auth

# DeepSeek (deepseek-chat, deepseek-coder, etc.)
# DEEPSEEK_API_KEY=sk-...

# Mistral (mistral-large, mistral-medium, etc.)
# MISTRAL_API_KEY=...

# Perplexity (pplx-70b-online, etc.)
# PERPLEXITY_API_KEY=pplx-...

# xAI (grok-1, etc.)
# XAI_API_KEY=...

# Cohere (command-r-plus, etc.)
# COHERE_API_KEY=...

# LiteLLM Proxy (if using self-hosted LiteLLM)
# LITELLM_API_BASE=http://localhost:4000
# LITELLM_API_KEY=...

# Azure OpenAI
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2024-02-15-preview